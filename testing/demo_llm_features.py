#!/usr/bin/env python3
"""
Demo script showing LLM switching capabilities
"""

from llm_providers import llm_manager
from llm_config import llm_config_manager

def main():
    print("ğŸŒŸ LLM Switching System Demo")
    print("=" * 50)
    
    # Show available models
    print("\nğŸ“‹ Available Models:")
    configs = llm_config_manager.get_available_configs()
    for config_id, config in configs.items():
        if config['is_active']:
            status = "âœ…" if config['has_api_key'] or config['provider'] != 'anthropic' else "âš ï¸"
            current = "â† CURRENT" if config['is_current'] else ""
            print(f"  {status} {config['display_name']} ({config['provider'].upper()}) {current}")
    
    print("\nğŸ”„ Testing Model Switching:")
    
    # Test each available model
    test_question = "What is 2+2? Answer in exactly 3 words."
    
    for config_id, config in configs.items():
        if not config['is_active']:
            continue
            
        print(f"\nğŸ¤– Switching to {config['display_name']}...")
        success = llm_manager.switch_provider(config_id)
        
        if success:
            try:
                messages = [{"role": "user", "content": test_question}]
                response = llm_manager.generate_response(messages, "Be concise and direct.")
                print(f"   Response: {response.strip()}")
            except Exception as e:
                print(f"   Error: {str(e)}")
        else:
            print(f"   Failed to switch to {config['display_name']}")
    
    # Show current status
    current = llm_manager.get_current_provider_info()
    print(f"\nğŸ¯ Final Status: Currently using {current['display_name']} ({current['provider'].upper()})")
    print(f"   Available: {'âœ…' if current['is_available'] else 'âŒ'}")
    
    print("\nğŸ“Š Provider Status:")
    status = llm_manager.get_provider_status()
    for provider_id, info in status.items():
        available = "âœ…" if info['is_available'] else "âŒ"
        current_mark = "â† CURRENT" if info['is_current'] else ""
        print(f"  {available} {info['display_name']} ({info['provider'].upper()}) {current_mark}")
    
    print("\nğŸ‰ Demo Complete! The LLM switching system is fully functional.")
    print("\nğŸ’¡ Key Features:")
    print("  â€¢ Auto-detection of available providers (Ollama detected âœ…)")
    print("  â€¢ Real-time model switching")
    print("  â€¢ Provider status monitoring")
    print("  â€¢ UI integration with settings page")
    print("  â€¢ Chat interface with model selector")
    print("  â€¢ API endpoints for programmatic control")

if __name__ == "__main__":
    main()